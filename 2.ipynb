{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Big Data Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying the Machine Learning Model on the processed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import random\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from transformers import ElectraTokenizer\n",
    "from transformers import ElectraForSequenceClassification, AdamW, BertConfig\n",
    "from keras.utils import pad_sequences\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import plotly.express as px\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the fake news and valid news dataset\n",
    "fake_news = pd.read_csv('Data_Approach1\\\\fake_news.csv')\n",
    "true_news = pd.read_csv('Data_Approach1\\\\true_news.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting the unanmed column\n",
    "true_news = true_news.drop(['Unnamed: 0'], axis=1)\n",
    "fake_news = fake_news.drop(['Unnamed: 0'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of fake news:  760\n",
      "Length of true news:  760\n"
     ]
    }
   ],
   "source": [
    "# Making both length equal in order to obtain an unbiased dataset.\n",
    "\n",
    "if len(fake_news) > len(true_news):\n",
    "    fake_news = fake_news.head(len(true_news))\n",
    "elif len(true_news) > len(fake_news):\n",
    "    true_news = true_news.head(len(fake_news))\n",
    "print(\"Length of fake news: \", len(fake_news))\n",
    "print(\"Length of true news: \", len(true_news))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Providing the labels as true = 1 and Fake = 0\n",
    "true_news['label'] = 1\n",
    "fake_news['label'] = 0\n",
    "news = pd.concat([fake_news, true_news])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>short_description</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>बूम पाय इमरान खान भारत सरकार आलोच रह वर्तमान श...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>सिख समुदाय के लोग हिंद साइन बोर्ड कालिख पोत दि...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>सोशल मीडिय प्लेटफ़ॉर्म फ़ेसबुक ट्विटर दाव के बड़ ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>दाव भाजप के मा सरकार जन के गलत रह</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>मीडिय आउटलेट्स वायर एजेंस गलत तरीक दाव किय पाक...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>चालक कार रोक के बजाय चल जार रख ट्रैफ़िक पुलिसक...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>मिसाइल 400 किलोमीटर ज़्याद मार सक</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>आकर्षण केंद्र वो शक्तिशाल पहलवान जिनक संबंध प्...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>बिहार के जातिगत समीकरण बात लंब बीजेप हिंद पहचा...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>एनआईए 83 साल के फ़ादर स्टेन स्वाम गिरफ़्तार यू...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1520 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     short_description  label\n",
       "0    बूम पाय इमरान खान भारत सरकार आलोच रह वर्तमान श...      0\n",
       "1    सिख समुदाय के लोग हिंद साइन बोर्ड कालिख पोत दि...      0\n",
       "2    सोशल मीडिय प्लेटफ़ॉर्म फ़ेसबुक ट्विटर दाव के बड़ ...      0\n",
       "3                   दाव भाजप के मा सरकार जन के गलत रह       0\n",
       "4    मीडिय आउटलेट्स वायर एजेंस गलत तरीक दाव किय पाक...      0\n",
       "..                                                 ...    ...\n",
       "755  चालक कार रोक के बजाय चल जार रख ट्रैफ़िक पुलिसक...      1\n",
       "756                 मिसाइल 400 किलोमीटर ज़्याद मार सक       1\n",
       "757  आकर्षण केंद्र वो शक्तिशाल पहलवान जिनक संबंध प्...      1\n",
       "758  बिहार के जातिगत समीकरण बात लंब बीजेप हिंद पहचा...      1\n",
       "759  एनआईए 83 साल के फ़ादर स्टेन स्वाम गिरफ़्तार यू...      1\n",
       "\n",
       "[1520 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffling the fake news and valid news using scikit learn shuffle\n",
    "news = shuffle(news)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Dataset: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>short_description</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>बयान कह प्रधानमंत्र जह मरीज़ मिल वो ट्रेनिंग हॉ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>मरियम नवाज़ लोग अपील वो हर हालत मीनार-ए-पाकिस्...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>लड़क लड़क शाद दोन लड़क लड़क प्यार</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>सोशल मीडिय दाव के अनुसार बिलकिस बान 19 दिन जेल</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>सब-डिविशनल मजिस्ट्रेट बूम बत वीडिय मॉक ड्रिल 1...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>बूम न्यूज़ रिपोर्ट्स पाई जिसम बत गय घट बांग्लाद...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>भान अथैय साल 1982 रिलीज़ फ़िल्म गांध कॉस्ट्यूम...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>बूम पाय वायरल तस्वीर एडिट गय असल तस्वीर 2016 व...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>बूम पाय तस्वीर असंबंधित घायल महिल तस्वीर गुजरात</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>दोन पक्ष आठ स्तर सैन्य वार् चुक सीम मुद्द सुलझ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1520 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     short_description  label\n",
       "318  बयान कह प्रधानमंत्र जह मरीज़ मिल वो ट्रेनिंग हॉ...      0\n",
       "368  मरियम नवाज़ लोग अपील वो हर हालत मीनार-ए-पाकिस्...      1\n",
       "109                 लड़क लड़क शाद दोन लड़क लड़क प्यार       1\n",
       "32     सोशल मीडिय दाव के अनुसार बिलकिस बान 19 दिन जेल       0\n",
       "499  सब-डिविशनल मजिस्ट्रेट बूम बत वीडिय मॉक ड्रिल 1...      0\n",
       "..                                                 ...    ...\n",
       "162  बूम न्यूज़ रिपोर्ट्स पाई जिसम बत गय घट बांग्लाद...      0\n",
       "751  भान अथैय साल 1982 रिलीज़ फ़िल्म गांध कॉस्ट्यूम...      1\n",
       "361  बूम पाय वायरल तस्वीर एडिट गय असल तस्वीर 2016 व...      0\n",
       "411   बूम पाय तस्वीर असंबंधित घायल महिल तस्वीर गुजरात       0\n",
       "219  दोन पक्ष आठ स्तर सैन्य वार् चुक सीम मुद्द सुलझ...      1\n",
       "\n",
       "[1520 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Final Dataset: \")\n",
    "news\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the final dataset to a csv file.\n",
    "news.to_csv('Data_Approach1\\\\Final_Dataset.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Get the GPU device name.\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the train test dataset using the scikit learn\n",
    "train, test, labels, y_test = train_test_split(\n",
    "    news, news['label'], test_size=0.2, stratify=news['label'], random_state=140, shuffle=True)\n",
    "\n",
    "# Storing the short description to sentences and label values in labels.\n",
    "sentences = train.short_description.values\n",
    "labels = labels.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer\n"
     ]
    }
   ],
   "source": [
    "# Load the BERT tokenizer.\n",
    "print('Loading BERT tokenizer')\n",
    "tokenizer = ElectraTokenizer.from_pretrained(\n",
    "    'monsoon-nlp/hindi-tpu-electra', do_lower_case=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bert Tokenizer: We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  वायरल तस्वीर चौक के बड़ा-स गद धनुष बाण बन देख सक \n",
      "Token IDs: [3, 18181, 7631, 8512, 1885, 0, 17, 480, 22357, 10573, 9872, 2214, 2473, 2050, 4]\n",
      "Original:  अजीत अंजुम बात के वायरल वीडिय सच्च पत लग पढ़ बूम रिपोर्ट \n",
      "Token IDs: [3, 14458, 8010, 2725, 2674, 1885, 18181, 38739, 1919, 6365, 2795, 2065, 0, 22699, 4643, 4]\n"
     ]
    }
   ],
   "source": [
    "# Tokenizing all of the sentences(separating the words) and map the tokens to thier word IDs.\n",
    "\n",
    "input_ids = []\n",
    "for sent in sentences:\n",
    "    encoded_sent = tokenizer.encode(\n",
    "        sent,\n",
    "        add_special_tokens=True,  # Add '[CLS]' and '[SEP]'\n",
    "        # max_length = 64,          # Truncate all sentences.\n",
    "        # return_tensors = 'pt',     # Return pytorch tensors.\n",
    "    )\n",
    "\n",
    "    # Add the encoded sentence to the list.\n",
    "    input_ids.append(encoded_sent)\n",
    "\n",
    "# Print sentence 0 and 1, now as a list of IDs.\n",
    "print('Original: ', sentences[0])\n",
    "print('Token IDs:', input_ids[0])\n",
    "print('Original: ', sentences[1])\n",
    "print('Token IDs:', input_ids[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the input ids\n",
    "seq_len = [len(sen) for sen in input_ids]\n",
    "pd.Series(seq_len).hist(bins=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sentence length:  49\n"
     ]
    }
   ],
   "source": [
    "# Checking the max length in input id\n",
    "print('Max sentence length: ', max([len(sen) for sen in input_ids]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Padding/truncating all sentences to 96 values...\n",
      "\n",
      "Padding token: \"[PAD]\", ID: 2\n",
      "\\Done.\n"
     ]
    }
   ],
   "source": [
    "# Set the maximum sequence length as 128 , as it should be slightly above 105\n",
    "\n",
    "MAX_LEN = 96\n",
    "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
    "print('\\nPadding token: \"{:}\", ID: {:}'.format(\n",
    "    tokenizer.pad_token, tokenizer.pad_token_id))\n",
    "\n",
    "# Pad our input tokens with value 0.\n",
    "# \"post\" indicates that we want to pad and truncate at the end of the sequence, as opposed to the beginning.\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\",\n",
    "                          value=0, truncating=\"post\", padding=\"post\")\n",
    "print('\\Done.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create attention masks\n",
    "\n",
    "attention_masks = []\n",
    "for sent in input_ids:\n",
    "\n",
    "    # Create the attention mask. If a token ID is 0, then it's padding, set the mask to 0. If a token ID is > 0, then it's a real token, set the mask to 1.\n",
    "    att_mask = [int(token_id > 0) for token_id in sent]\n",
    "\n",
    "    # Store the attention mask for this sentence.\n",
    "    attention_masks.append(att_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use train_test_split to split our data into train and validation sets for training, 10% validation\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels,\n",
    "                                                                                    random_state=140, test_size=0.1)\n",
    "# Do the same for the masks.\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
    "                                                       random_state=140, test_size=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all inputs and labels into torch tensors, the required datatype for our model.\n",
    "\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The DataLoader needs to know our batch size for training, so we specify it here.\n",
    "batch_size = 16\n",
    "\n",
    "# Create the DataLoader for our training set.\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(\n",
    "    train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set.\n",
    "validation_data = TensorDataset(\n",
    "    validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(\n",
    "    validation_data, sampler=validation_sampler, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  0% |\n",
      "GPU Usage after emptying the cache\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  2% |  2% |\n"
     ]
    }
   ],
   "source": [
    "# Code snippet for deleting the gpu cache\n",
    "from GPUtil import showUtilization as gpu_usage\n",
    "from numba import cuda\n",
    "\n",
    "\n",
    "def free_gpu_cache():\n",
    "    print(\"Initial GPU Usage\")\n",
    "    gpu_usage()\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    cuda.select_device(0)\n",
    "    cuda.close()\n",
    "    cuda.select_device(0)\n",
    "\n",
    "    print(\"GPU Usage after emptying the cache\")\n",
    "    gpu_usage()\n",
    "\n",
    "\n",
    "free_gpu_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at monsoon-nlp/hindi-tpu-electra were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.weight']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monsoon-nlp/hindi-tpu-electra and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ElectraForSequenceClassification(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(39628, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): ElectraClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load BertForSequenceClassification, the pretrained BERT model with a single linear classification layer on top.\n",
    "\n",
    "model = ElectraForSequenceClassification.from_pretrained(\n",
    "    # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    \"monsoon-nlp/hindi-tpu-electra\",\n",
    "    num_labels=2,  # The number of output labels--2 for binary classification.\n",
    "    output_attentions=False,  # Whether the model returns attentions weights.\n",
    "    output_hidden_states=False,  # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BERT model has 201 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "electra.embeddings.word_embeddings.weight               (39628, 768)\n",
      "electra.embeddings.position_embeddings.weight             (512, 768)\n",
      "electra.embeddings.token_type_embeddings.weight             (2, 768)\n",
      "electra.embeddings.LayerNorm.weight                           (768,)\n",
      "electra.embeddings.LayerNorm.bias                             (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "electra.encoder.layer.0.attention.self.query.weight       (768, 768)\n",
      "electra.encoder.layer.0.attention.self.query.bias             (768,)\n",
      "electra.encoder.layer.0.attention.self.key.weight         (768, 768)\n",
      "electra.encoder.layer.0.attention.self.key.bias               (768,)\n",
      "electra.encoder.layer.0.attention.self.value.weight       (768, 768)\n",
      "electra.encoder.layer.0.attention.self.value.bias             (768,)\n",
      "electra.encoder.layer.0.attention.output.dense.weight     (768, 768)\n",
      "electra.encoder.layer.0.attention.output.dense.bias           (768,)\n",
      "electra.encoder.layer.0.attention.output.LayerNorm.weight       (768,)\n",
      "electra.encoder.layer.0.attention.output.LayerNorm.bias       (768,)\n",
      "electra.encoder.layer.0.intermediate.dense.weight        (3072, 768)\n",
      "electra.encoder.layer.0.intermediate.dense.bias              (3072,)\n",
      "electra.encoder.layer.0.output.dense.weight              (768, 3072)\n",
      "electra.encoder.layer.0.output.dense.bias                     (768,)\n",
      "electra.encoder.layer.0.output.LayerNorm.weight               (768,)\n",
      "electra.encoder.layer.0.output.LayerNorm.bias                 (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "classifier.dense.weight                                   (768, 768)\n",
      "classifier.dense.bias                                         (768,)\n",
      "classifier.out_proj.weight                                  (2, 768)\n",
      "classifier.out_proj.bias                                        (2,)\n"
     ]
    }
   ],
   "source": [
    "# Get all of the model's parameters as a list of tuples.\n",
    "# Summary of the Model\n",
    "\n",
    "params = list(model.named_parameters())\n",
    "print('The BERT model has {:} different named parameters.\\n'.format(\n",
    "    len(params)))\n",
    "print('==== Embedding Layer ====\\n')\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "for p in params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bhavy\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Note: AdamW is a class from the huggingface library (as opposed to pytorch)\n",
    "# Adam is the optimizer for our model\n",
    "\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr=2e-5,  # args.learning_rate\n",
    "                  eps=1e-8  # args.adam_epsilon  - default is 1e-8.\n",
    "                  )\n",
    "\n",
    "epochs = 5\n",
    "# Total number of training steps is number of batches * number of epochs.\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                            num_warmup_steps=0,\n",
    "                                            num_training_steps=total_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the time elapsed in one iteration\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "\n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 5 ========\n",
      "Training...\n",
      "  Batch    40  of     69.    Elapsed: 0:00:31.\n",
      "\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:47\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.41\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 2 / 5 ========\n",
      "Training...\n",
      "  Batch    40  of     69.    Elapsed: 0:00:23.\n",
      "\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:39\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.41\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 3 / 5 ========\n",
      "Training...\n",
      "  Batch    40  of     69.    Elapsed: 0:00:23.\n",
      "\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:40\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.41\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 4 / 5 ========\n",
      "Training...\n",
      "  Batch    40  of     69.    Elapsed: 0:00:24.\n",
      "\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:41\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.41\n",
      "  Validation took: 0:00:02\n",
      "\n",
      "======== Epoch 5 / 5 ========\n",
      "Training...\n",
      "  Batch    40  of     69.    Elapsed: 0:00:24.\n",
      "\n",
      "  Average training loss: 0.69\n",
      "  Training epcoh took: 0:00:41\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.41\n",
      "  Validation took: 0:00:02\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Actual training tf the model\n",
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "# Store the average loss after each epoch so we can plot them.\n",
    "loss_values = []\n",
    "start = time.time()\n",
    "for epoch_i in range(0, epochs):\n",
    "\n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "    t0 = time.time()\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(\n",
    "                step, len(train_dataloader), elapsed))\n",
    "        # Unpack this training batch from our dataloader.\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids\n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        # Always clear any previously calculated gradients before performing a backward pass.\n",
    "\n",
    "        model.zero_grad()\n",
    "        # Perform a forward pass .This will return the loss .\n",
    "        outputs = model(b_input_ids,\n",
    "                        token_type_ids=None,\n",
    "                        attention_mask=b_input_mask,\n",
    "                        labels=b_labels)\n",
    "\n",
    "        # The call to `model` always returns a tuple, so we need to pull the loss value out of the tuple.\n",
    "        loss = outputs[0]\n",
    "        # Accumulate the training loss over all of the batches so that we can calculate the average loss at the end. `loss` is a Tensor containing a single value\n",
    "        total_loss += loss.item()\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "        # Clip the norm of the gradients to 1.0. This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        optimizer.step()\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "    # Calculate the average loss over the training data.\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "    # Store the loss value for plotting the learning curve.\n",
    "    loss_values.append(avg_train_loss)\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on our validation set.\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "    t0 = time.time()\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently during evaluation.\n",
    "    model.eval()\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    for batch in validation_dataloader:\n",
    "\n",
    "        # Add batch to GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        # Telling the model not to compute or store gradients, saving memory and  speeding up validation\n",
    "        with torch.no_grad():\n",
    "            # Forward pass, calculate logit predictions. This will return the logits rather than the loss because we have not provided labels.\n",
    "            # token_type_ids is the same as the \"segment ids\"\n",
    "            outputs = model(b_input_ids,\n",
    "                            token_type_ids=None,\n",
    "                            attention_mask=b_input_mask)\n",
    "\n",
    "        # Get the \"logits\" output by the model.\n",
    "        logits = outputs[0]\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # Calculate the accuracy for this batch of test sentences.\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "\n",
    "        # Accumulate the total accuracy.\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        # Track the number of batches\n",
    "        nb_eval_steps += 1\n",
    "    # Report the final accuracy for this validation run.\n",
    "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "end = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "index=%{x}<br>Loss=%{y}<extra></extra>",
         "legendgroup": "",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4
         ],
         "xaxis": "x",
         "y": [
          0.6932219992513242,
          0.6931226780449135,
          0.6931228378544683,
          0.6931886577951736,
          0.6930942924126334
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Training loss of the Model"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Epoch"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Loss"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the graph of loss vs the epoch\n",
    "\n",
    "f = pd.DataFrame(loss_values)\n",
    "f.columns = ['Loss']\n",
    "fig = px.line(f, x=f.index, y=f.Loss)\n",
    "fig.update_layout(title='Training loss of the Model',\n",
    "                  xaxis_title='Epoch',\n",
    "                  yaxis_title='Loss')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "sentences = test.short_description.values\n",
    "labels = y_test.values\n",
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids = []\n",
    "for sent in sentences:\n",
    "\n",
    "    encoded_sent = tokenizer.encode(\n",
    "        sent,                      # Sentence to encode.\n",
    "        add_special_tokens=True,  # Add '[CLS]' and '[SEP]'\n",
    "        max_length=256\n",
    "    )\n",
    "\n",
    "    input_ids.append(encoded_sent)\n",
    "# Pad our input tokens\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN,\n",
    "                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "# Create attention masks\n",
    "attention_masks = []\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in input_ids:\n",
    "    seq_mask = [float(i > 0) for i in seq]\n",
    "    attention_masks.append(seq_mask)\n",
    "# Convert to tensors.\n",
    "prediction_inputs = torch.tensor(input_ids)\n",
    "prediction_masks = torch.tensor(attention_masks)\n",
    "prediction_labels = torch.tensor(labels)\n",
    "# Set the batch size.\n",
    "batch_size = 32\n",
    "# Create the DataLoader.\n",
    "prediction_data = TensorDataset(\n",
    "    prediction_inputs, prediction_masks, prediction_labels)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(\n",
    "    prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for 304 test sentences...\n",
      "DONE.\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model and predicting the labels for new sentences\n",
    "\n",
    "print('Predicting labels for {:,} test sentences...'.format(\n",
    "    len(prediction_inputs)))\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "predictions, true_labels = [], []\n",
    "# Predict\n",
    "for batch in prediction_dataloader:\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Forward pass, calculate logit predictions\n",
    "        outputs = model(b_input_ids, token_type_ids=None,\n",
    "                        attention_mask=b_input_mask)\n",
    "    logits = outputs[0]\n",
    "    # Move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "    # Store predictions and true labels\n",
    "    predictions.append(logits)\n",
    "    true_labels.append(label_ids)\n",
    "print('DONE.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the accuracy of the model\n",
    "\n",
    "count = 0\n",
    "guesses = []\n",
    "actual = []\n",
    "# For each input batch...\n",
    "for i in range(len(true_labels)):\n",
    "\n",
    "    # The predictions for this batch are a 2-column ndarray (one column for \"0\" and one column for \"1\"). Pick the label with the highest value and turn this in to a list of 0s and 1s.\n",
    "    pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
    "\n",
    "    # calculate accuracy\n",
    "    for j in range(len(pred_labels_i)):\n",
    "        if(pred_labels_i[j] == true_labels[i][j]):\n",
    "            count += 1\n",
    "        guesses.append(pred_labels_i[j])\n",
    "        actual.append(true_labels[i][j])\n",
    "\n",
    "\n",
    "accuracy = count/len(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "50.0 %\n"
     ]
    }
   ],
   "source": [
    "# Prinitng the Accuracy of the model\n",
    "print(accuracy)\n",
    "print(accuracy*100, '%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "1.0\n",
      "0.5\n",
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(actual, guesses))\n",
    "print(recall_score(actual, guesses))\n",
    "print(precision_score(actual, guesses))\n",
    "print(f1_score(actual, guesses))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ee691e3c2883c6a130fe7a4fe904a1eaf00aeea2af805a016ed0d0bd8e74479"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
